{"cells":[{"cell_type":"markdown","id":"AoeSkz4KaANH","metadata":{"id":"AoeSkz4KaANH"},"source":["# <center> Predicting a Biological Response\n","<center> <img src=\"https://www.cancerquest.org/sites/default/files/2021-04%20more/Biological_Approach_Sq.gif\" width=\"300\" height=\"300\">"]},{"cell_type":"markdown","id":"7659eddf","metadata":{},"source":["The project is based on the [Kaggle: Predicting a Biological Response](https://www.kaggle.com/c/bioresponse) Competition\n","\n","The objective of the competition is to help us build as good a model as possible so that we can, as optimally as this data allows, relate molecular information, to an actual biological response.\n","\n","Each line represents a molecula. \n","\n","The first column (Activity) describes the experiment data - the biological response [0, 1];\n","\n","The rest of the columns (D1 through D1776) represent molecular descriptors these are caclulated properties that can capture some of the characteristics of the molecule - for example size, shape, or elemental constitution."]},{"cell_type":"markdown","id":"203fb80e-a314-4876-850c-5e4913f78563","metadata":{"id":"203fb80e-a314-4876-850c-5e4913f78563","tags":[]},"source":["______________________________________________________\n","\n","We will build the ML model using both the Logistic Regression and Random Forest methods.\n","\n","We will also optimise the hyperparametors for these methods using four different techniques:\n","- GridSeachCV,\n","- RandomizedSearchCV,\n","- Hyperopt,\n","- Optuna"]},{"cell_type":"code","execution_count":1,"id":"d8q91-MSaAOG","metadata":{"id":"d8q91-MSaAOG"},"outputs":[],"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import linear_model\n","from sklearn import tree\n","from sklearn import ensemble\n","from sklearn import metrics\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline\n","plt.style.use('seaborn')"]},{"cell_type":"markdown","id":"8lbyun1kaAOy","metadata":{"id":"8lbyun1kaAOy","jp-MarkdownHeadingCollapsed":true,"tags":[]},"source":["## Data Loading"]},{"cell_type":"code","execution_count":2,"id":"p770SmlfaAO3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"executionInfo":{"elapsed":40242,"status":"ok","timestamp":1650553529870,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"p770SmlfaAO3","outputId":"d6f8209e-05bf-452c-dd16-2f5725c31f1a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Activity</th>\n","      <th>D1</th>\n","      <th>D2</th>\n","      <th>D3</th>\n","      <th>D4</th>\n","      <th>D5</th>\n","      <th>D6</th>\n","      <th>D7</th>\n","      <th>D8</th>\n","      <th>D9</th>\n","      <th>...</th>\n","      <th>D1767</th>\n","      <th>D1768</th>\n","      <th>D1769</th>\n","      <th>D1770</th>\n","      <th>D1771</th>\n","      <th>D1772</th>\n","      <th>D1773</th>\n","      <th>D1774</th>\n","      <th>D1775</th>\n","      <th>D1776</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.497009</td>\n","      <td>0.10</td>\n","      <td>0.0</td>\n","      <td>0.132956</td>\n","      <td>0.678031</td>\n","      <td>0.273166</td>\n","      <td>0.585445</td>\n","      <td>0.743663</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.366667</td>\n","      <td>0.606291</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.111209</td>\n","      <td>0.803455</td>\n","      <td>0.106105</td>\n","      <td>0.411754</td>\n","      <td>0.836582</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.033300</td>\n","      <td>0.480124</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.209791</td>\n","      <td>0.610350</td>\n","      <td>0.356453</td>\n","      <td>0.517720</td>\n","      <td>0.679051</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows Ã— 1777 columns</p>\n","</div>"],"text/plain":["   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n","0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n","1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n","2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n","\n","         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n","0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n","1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n","2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n","\n","   D1774  D1775  D1776  \n","0      0      0      0  \n","1      0      1      0  \n","2      0      0      0  \n","\n","[3 rows x 1777 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('/home/mike/Documents/Coding/Data/ML - Predicting a Biological Response/_train_sem09.csv')\n","\n","data.head(3)"]},{"cell_type":"code","execution_count":3,"id":"-0L4fYsbaAPP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1650553529889,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"-0L4fYsbaAPP","outputId":"e5f3ce35-3c90-428a-9831-27dda4dd292c"},"outputs":[{"data":{"text/plain":["Activity    0\n","D1          0\n","D2          0\n","D3          0\n","D4          0\n","           ..\n","D1772       0\n","D1773       0\n","D1774       0\n","D1775       0\n","D1776       0\n","Length: 1777, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()"]},{"cell_type":"markdown","id":"0jbyUoPlaAPc","metadata":{"id":"0jbyUoPlaAPc"},"source":["Check if the data is well-balanced"]},{"cell_type":"code","execution_count":4,"id":"PPo2xmRdaAPf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1650553530901,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"PPo2xmRdaAPf","outputId":"4db04fd7-a921-4f20-ce92-b8294d0f3d2a"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.countplot(data=data, x='Activity');"]},{"cell_type":"markdown","id":"8p3eELnEaAQW","metadata":{"id":"8p3eELnEaAQW"},"source":["Creating an observation matrix $X$ and a vector of answers $y$"]},{"cell_type":"code","execution_count":7,"id":"_2GncsCbaAQY","metadata":{"id":"_2GncsCbaAQY"},"outputs":[],"source":["X = data.drop(['Activity'], axis=1)\n","y = data['Activity']"]},{"cell_type":"markdown","id":"q4SyRSFhaAQZ","metadata":{"id":"q4SyRSFhaAQZ"},"source":["Split the dataset into a train and test sets 80/20. Use stratify split to maintain the distribution of the target parameter."]},{"cell_type":"code","execution_count":8,"id":"Fl_eJIInaAQa","metadata":{"id":"Fl_eJIInaAQa"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42, test_size = 0.2)"]},{"cell_type":"markdown","id":"H7DZBta2aAQf","metadata":{"id":"H7DZBta2aAQf","tags":[]},"source":["## Optimise the hyperparameters"]},{"cell_type":"markdown","id":"CE7v-medaAQh","metadata":{"id":"CE7v-medaAQh","tags":[]},"source":["## Logistic Regression"]},{"cell_type":"markdown","id":"5b6d603a-1ce0-414e-b095-e0f61113c0e7","metadata":{"id":"5b6d603a-1ce0-414e-b095-e0f61113c0e7"},"source":["Set the banchmark using by-default parameters of LogisticRegression()"]},{"cell_type":"code","execution_count":11,"id":"0aMCHU3-aAQn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1650547896821,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"0aMCHU3-aAQn","outputId":"ce2823fa-1cb5-4ec5-dd51-fec74d3ccd33"},"outputs":[{"name":"stdout","output_type":"stream","text":["The test set accuracy is 0.75\n","f1_score for the test set is 0.78\n"]},{"name":"stderr","output_type":"stream","text":["/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["#Create the logistic-regression class object\n","log_reg = linear_model.LogisticRegression(max_iter = 50)\n","#Train the model by minimizing logloss\n","log_reg.fit(X_train, y_train)\n","print(\"The test set accuracy is {:.2f}\".format(log_reg.score(X_test, y_test)))\n","y_test_pred = log_reg.predict(X_test)\n","print('f1_score for the test set is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"Q6PP7ObJp7WG","metadata":{"id":"Q6PP7ObJp7WG"},"source":["### <center> **GridSearchCV**"]},{"cell_type":"code","execution_count":24,"id":"gLkG_sbSkBcu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71581,"status":"ok","timestamp":1650547968248,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"gLkG_sbSkBcu","outputId":"9bf92017-3d32-43fd-f801-9533285646b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["The test set accuracy after GridSearchCV parameter optimisation is 0.76\n","f1_score for the test set after GridSearchCV parameter optimisation is 0.78\n","The best hyperparameters according to GridSearchCV are {'penalty': 'l2', 'solver': 'saga'}\n"]},{"name":"stderr","output_type":"stream","text":["/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {'penalty': ['l2', 'none'], #penalty type\n","              'solver': ['lbfgs', 'saga'], # optimisation algorithm\n","              }\n","\n","grid_search = GridSearchCV(\n","    estimator=linear_model.LogisticRegression(\n","        random_state=42,\n","        max_iter=50 #the number of iterations is so low for training purposes\n","    ), \n","    param_grid=param_grid, \n","    cv=5, \n","    n_jobs = -1\n",")\n","\n","# Calculate the metrics\n","grid_search.fit(X_train, y_train)\n","print(\"The test set accuracy after GridSearchCV parameter optimisation is {:.2f}\".format(grid_search.score(X_test, y_test)))\n","y_test_pred = grid_search.predict(X_test)\n","print('f1_score for the test set after GridSearchCV parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n","print(\"The best hyperparameters according to GridSearchCV are {}\".format(grid_search.best_params_))"]},{"cell_type":"markdown","id":"QOlWE5zSptj0","metadata":{"id":"QOlWE5zSptj0"},"source":["### <center> **RandomizedSearchCV**"]},{"cell_type":"code","execution_count":29,"id":"4yjUJJKntcX7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67382,"status":"ok","timestamp":1650548481134,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"4yjUJJKntcX7","outputId":"c7964d60-9c70-42f4-8f0c-217d9e568ddc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 40 is smaller than n_iter=50. Running 40 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["The test set accuracy after RandomizedSearchCV parameter optimisation is 0.75\n","f1_score for the test set after RandomizedSearchCV parameter optimisation is 0.78\n","The best hyperparameters according to RandomizedSearchCV are {'solver': 'sag', 'penalty': 'l2', 'C': 0.01}\n"]},{"name":"stderr","output_type":"stream","text":["/home/mike/anaconda3/envs/sf/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","param_grid = {'penalty': ['l2', 'none'] ,\n","              'solver': ['lbfgs', 'sag'],\n","               'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n","            \n","random_search = RandomizedSearchCV(\n","    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n","    param_distributions=param_grid, \n","    cv=5, \n","    n_iter = 10, \n","    n_jobs = -1\n",")\n","\n","# Calculate the metrics\n","random_search.fit(X_train, y_train) \n","print(\"The test set accuracy after RandomizedSearchCV parameter optimisation is {:.2f}\".format(random_search.score(X_test, y_test)))\n","y_test_pred = random_search.predict(X_test)\n","print('f1_score for the test set after RandomizedSearchCV parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n","print(\"The best hyperparameters according to RandomizedSearchCV are {}\".format(random_search.best_params_))"]},{"cell_type":"markdown","id":"6230df7f","metadata":{},"source":["### <center> **Hyperopt**"]},{"cell_type":"code","execution_count":31,"id":"8a577569","metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","import hyperopt\n","from hyperopt import hp, fmin, tpe, Trials"]},{"cell_type":"code","execution_count":33,"id":"bc6a6f47","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:54<00:00,  2.73s/trial, best loss: -0.9743433109346366]\n","f1_score for the test set after Hyperopt parameter optimisation is 0.79\n"]}],"source":["trials = Trials() # for results logging\n","\n","space={'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n","       'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n","       'min_samples_leaf': hp.quniform('min_samples_leaf', 3, 7, 1)\n","      }\n","\n","def hyperopt_gb(params, cv=5, X=X_train, y=y_train, random_state=42):\n","    # the function receives the hyperparameters combination through \"params\"\n","    params = {'n_estimators': int(params['n_estimators']), \n","              'max_depth': int(params['max_depth']), \n","              'min_samples_leaf': int(params['min_samples_leaf'])\n","              }\n","    # use this combination to build the model\n","    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n"," \n","    # Train the model\n","    model.fit(X, y)\n","    score = metrics.f1_score(y, model.predict(X))\n","    # The metrics should be minimised, therefore we add '-' at the beginning\n","    return -score\n"," \n","    # Begin selection of hyperparameters\n","best=fmin(hyperopt_gb, # the function\n","          space=space, # the space of hyperparameters\n","          algo=tpe.suggest, # optimisation algorythm (by default)\n","          max_evals=20, # max number of iterations\n","          trials=trials, # result logging\n","          rstate=np.random.default_rng(42)\n","         )\n"," \n","# Calculate the metrics\n","model = ensemble.RandomForestClassifier(random_state=42, \n","                                        n_estimators=int(best['n_estimators']),   \n","                                        max_depth=int(best['max_depth']),\n","                                        min_samples_leaf=int(best['min_samples_leaf']))\n","model.fit(X_train, y_train)\n","y_test_pred = model.predict(X_test)\n","print('f1_score for the test set after Hyperopt parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"55307738","metadata":{},"source":["## <center> Optuna"]},{"cell_type":"code","execution_count":34,"id":"55c27b67","metadata":{},"outputs":[],"source":["import optuna"]},{"cell_type":"code","execution_count":35,"id":"860d4909","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-06-14 00:29:34,777]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:36,542]\u001b[0m Trial 0 finished with value: 0.9895769466584917 and parameters: {'n_estimators': 101, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.9895769466584917.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:38,613]\u001b[0m Trial 1 finished with value: 0.94092439546985 and parameters: {'n_estimators': 143, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9895769466584917.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:41,199]\u001b[0m Trial 2 finished with value: 0.9438339438339438 and parameters: {'n_estimators': 185, 'max_depth': 18, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9895769466584917.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:42,681]\u001b[0m Trial 3 finished with value: 0.9334144116752812 and parameters: {'n_estimators': 102, 'max_depth': 14, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9895769466584917.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:46,013]\u001b[0m Trial 4 finished with value: 0.9917101627264354 and parameters: {'n_estimators': 197, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:47,654]\u001b[0m Trial 5 finished with value: 0.9509295946357817 and parameters: {'n_estimators': 110, 'max_depth': 16, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:49,014]\u001b[0m Trial 6 finished with value: 0.9156773211567731 and parameters: {'n_estimators': 104, 'max_depth': 16, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:51,180]\u001b[0m Trial 7 finished with value: 0.938489646772229 and parameters: {'n_estimators': 153, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:53,739]\u001b[0m Trial 8 finished with value: 0.9749388753056235 and parameters: {'n_estimators': 166, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:55,538]\u001b[0m Trial 9 finished with value: 0.9101978691019786 and parameters: {'n_estimators': 138, 'max_depth': 22, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:29:57,871]\u001b[0m Trial 10 finished with value: 0.8940961655508217 and parameters: {'n_estimators': 198, 'max_depth': 30, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:00,083]\u001b[0m Trial 11 finished with value: 0.990499540300337 and parameters: {'n_estimators': 130, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:02,188]\u001b[0m Trial 12 finished with value: 0.9895833333333333 and parameters: {'n_estimators': 126, 'max_depth': 29, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:04,763]\u001b[0m Trial 13 finished with value: 0.9743746186699207 and parameters: {'n_estimators': 167, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:07,052]\u001b[0m Trial 14 finished with value: 0.9898804047838086 and parameters: {'n_estimators': 130, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:09,001]\u001b[0m Trial 15 finished with value: 0.9214241866175569 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:10,590]\u001b[0m Trial 16 finished with value: 0.9202678027997565 and parameters: {'n_estimators': 120, 'max_depth': 26, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:12,844]\u001b[0m Trial 17 finished with value: 0.8955859969558599 and parameters: {'n_estimators': 187, 'max_depth': 28, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:15,495]\u001b[0m Trial 18 finished with value: 0.9570514773073409 and parameters: {'n_estimators': 176, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n","\u001b[32m[I 2022-06-14 00:30:17,771]\u001b[0m Trial 19 finished with value: 0.9558868268938242 and parameters: {'n_estimators': 143, 'max_depth': 20, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9917101627264354.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["f1_score for the test set after Optuna parameter optimisation is 0.80\n"]}],"source":["# set the hyperparameters search space\n","space={'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n","       'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n","       'min_samples_leaf': hp.quniform('min_samples_leaf', 3, 7, 1)\n","      }\n","\n","def optuna_rf(trial):\n","  # set the hyperparameters search space\n","  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n","  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n","  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n","  # build the model\n","  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n","                                          max_depth=max_depth,\n","                                          min_samples_leaf=min_samples_leaf,\n","                                          random_state=42)\n","  # train the model\n","  model.fit(X_train, y_train)\n","  score = metrics.f1_score(y_train, model.predict(X_train))\n","  return score\n","\n","# create the research object\n","study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n","# searching the best hyperparameters combination 'n_trials' times\n","study.optimize(optuna_rf, n_trials=20)\n","\n","# Calculate the metrics\n","model = ensemble.RandomForestClassifier(**study.best_params,random_state=42, )\n","model.fit(X_train, y_train)\n","y_test_pred = model.predict(X_test)\n","print('f1_score for the test set after Optuna parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"9155bbe4","metadata":{},"source":["## Random Forest"]},{"cell_type":"markdown","id":"-4-TPHjgTBOs","metadata":{"id":"-4-TPHjgTBOs"},"source":["Set the banchmark using by-default parameters of RandomForestClassifier()"]},{"cell_type":"code","execution_count":38,"id":"XUYSiTfraARA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5007,"status":"ok","timestamp":1650551264191,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"XUYSiTfraARA","outputId":"5332fa04-ad32-4791-a3f7-163fad39406c"},"outputs":[{"name":"stdout","output_type":"stream","text":["f1_score for the test set (Random Forest, default parameters) is 0.80\n"]}],"source":["#Create the Random Forest class object\n","rf = ensemble.RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","rf.fit(X_train, y_train)\n","\n","# Calculate the metrics \n","y_test_pred = rf.predict(X_test)\n","print('f1_score for the test set (Random Forest, default parameters) is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"fcc7e373","metadata":{},"source":["## <center> GridSearchCV "]},{"cell_type":"code","execution_count":39,"id":"5e7f9835","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["f1_score for the test set after GridSearchCV parameter optimisation is 0.80\n","The best Random Forest hyperparameters according to GridSearchCV are {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"]}],"source":["# Set up the hyperparameters grid\n","param_grid = {'n_estimators': list(range(80, 200, 30)), # the number of trees in the forest\n","              'min_samples_leaf': [5], # the minimum number of samples required to be at a leaf node\n","              'max_depth': list(np.linspace(20, 40, 5, dtype=int)) # the maximum depth of the tree\n","              }\n","            \n","grid_search_forest = GridSearchCV(\n","    estimator=ensemble.RandomForestClassifier(random_state=42), \n","    param_grid=param_grid, \n","    cv=5, \n","    n_jobs = -1\n",")  \n","\n","# Calculate the metrics \n","grid_search_forest.fit(X_train, y_train) \n","y_test_pred = grid_search_forest.predict(X_test)\n","print('f1_score for the test set after GridSearchCV parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n","print(\"The best Random Forest hyperparameters according to GridSearchCV are {}\".format(grid_search_forest.best_params_))"]},{"cell_type":"markdown","id":"a2ad3ed9","metadata":{},"source":["## <center> RandomizedSearchCV "]},{"cell_type":"code","execution_count":40,"id":"TBSxQJ6JzS1f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116021,"status":"ok","timestamp":1650551380171,"user":{"displayName":"VICDS _","userId":"16539764637744847477"},"user_tz":-180},"id":"TBSxQJ6JzS1f","outputId":"ecddf908-16fb-4ccb-88dc-025270b99d05"},"outputs":[{"name":"stdout","output_type":"stream","text":["f1_score for the test set after RandomizedSearchCV parameter optimisation is 0.80\n","The best Random Forest hyperparameters according to RandomizedSearchCV are {'n_estimators': 170, 'min_samples_leaf': 5, 'max_depth': 22}\n"]}],"source":["param_grid = {'n_estimators': list(range(80, 200, 30)),\n","              'min_samples_leaf': [5],\n","              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n","              }\n","            \n","random_search_forest = RandomizedSearchCV(\n","    estimator=ensemble.RandomForestClassifier(random_state=42), \n","    param_distributions=param_grid, \n","    cv=5,\n","    n_iter = 10, \n","    n_jobs = -1\n",")  \n","\n","# Calculate the metrics \n","random_search_forest.fit(X_train, y_train) \n","y_test_pred = random_search_forest.predict(X_test)\n","print('f1_score for the test set after RandomizedSearchCV parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n","print(\"The best Random Forest hyperparameters according to RandomizedSearchCV are {}\".format(random_search_forest.best_params_))"]},{"cell_type":"markdown","id":"Kmo2b6kPChhN","metadata":{"id":"Kmo2b6kPChhN"},"source":["### <center> Hyperopt"]},{"cell_type":"code","execution_count":41,"id":"8dWxW_9K_qJp","metadata":{"id":"8dWxW_9K_qJp"},"outputs":[],"source":["# Set up the hyperparameters search space\n","space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n","       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n","       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n","      }"]},{"cell_type":"code","execution_count":52,"id":"962f9817","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.01s/trial, best loss: -0.9868380777471687]\n","f1_score for the test set after Hyperopt parameter optimisation is 0.81\n"]}],"source":["# create a function to minimize the metric,\n","# the function receives a dictionary of hyperparameter values and returns the value of the target function\n","def hyperopt_gb(params, cv=5, X=X_train, y=y_train, random_state=42):\n","    # the function receives a combination of hyperparameter in \"params\"\n","    params = {'n_estimators': int(params['n_estimators']), \n","              'max_depth': int(params['max_depth']), \n","              'min_samples_leaf': int(params['min_samples_leaf'])\n","              }\n","    # use this combination to build the model\n","    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n"," \n","    # train the model\n","    model.fit(X, y)\n","    score = metrics.f1_score(y, model.predict(X))\n","    \n","    # the metrics should be minimised, therefore we add '-' at the beginning\n","    return -score\n"," \n","trials = Trials() # for result logging\n"," \n","# begin the selection of hyperparameters\n","best=fmin(hyperopt_gb, # the function \n","          space=space, # the space of hyperparameters\n","          algo=tpe.suggest, # optimisation algorythm (by default)\n","          max_evals=20, # max number of iterations\n","          trials=trials, # result logging\n","          rstate=np.random.default_rng(42)\n","         )\n"," \n","# calculate the metrics\n","model = ensemble.RandomForestClassifier(random_state=42, \n","                                        n_estimators=int(best['n_estimators']),   \n","                                        max_depth=int(best['max_depth']),\n","                                        min_samples_leaf=int(best['min_samples_leaf']))\n","model.fit(X_train, y_train)\n","y_test_pred = model.predict(X_test)\n","print('f1_score for the test set after Hyperopt parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"b8734d51-d5d5-4424-b8a3-b341dde985b5","metadata":{"id":"b8734d51-d5d5-4424-b8a3-b341dde985b5"},"source":["## <center> Optuna"]},{"cell_type":"code","execution_count":50,"id":"3455d6c1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-06-14 23:19:17,748]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:19,805]\u001b[0m Trial 0 finished with value: 0.89592209373098 and parameters: {'n_estimators': 170, 'max_depth': 29, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.89592209373098.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:22,370]\u001b[0m Trial 1 finished with value: 0.9746719560573696 and parameters: {'n_estimators': 166, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:23,748]\u001b[0m Trial 2 finished with value: 0.8899755501222495 and parameters: {'n_estimators': 120, 'max_depth': 10, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:25,778]\u001b[0m Trial 3 finished with value: 0.9500912964090079 and parameters: {'n_estimators': 138, 'max_depth': 16, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:27,952]\u001b[0m Trial 4 finished with value: 0.9643835616438357 and parameters: {'n_estimators': 146, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:30,489]\u001b[0m Trial 5 finished with value: 0.9659160073037127 and parameters: {'n_estimators': 170, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:33,425]\u001b[0m Trial 6 finished with value: 0.9709923664122138 and parameters: {'n_estimators': 193, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:35,522]\u001b[0m Trial 7 finished with value: 0.91047503045067 and parameters: {'n_estimators': 164, 'max_depth': 20, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:37,165]\u001b[0m Trial 8 finished with value: 0.9408519767085505 and parameters: {'n_estimators': 120, 'max_depth': 13, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9746719560573696.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:40,044]\u001b[0m Trial 9 finished with value: 0.975 and parameters: {'n_estimators': 187, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.975.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:42,685]\u001b[0m Trial 10 finished with value: 0.9304878048780487 and parameters: {'n_estimators': 197, 'max_depth': 25, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.975.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:45,610]\u001b[0m Trial 11 finished with value: 0.9911015648972077 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9911015648972077.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:48,611]\u001b[0m Trial 12 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 183, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:51,703]\u001b[0m Trial 13 finished with value: 0.9910961007061714 and parameters: {'n_estimators': 184, 'max_depth': 24, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:54,195]\u001b[0m Trial 14 finished with value: 0.9463741620962828 and parameters: {'n_estimators': 179, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:56,664]\u001b[0m Trial 15 finished with value: 0.9901900674432864 and parameters: {'n_estimators': 151, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:19:58,896]\u001b[0m Trial 16 finished with value: 0.9439366240097502 and parameters: {'n_estimators': 156, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:20:00,257]\u001b[0m Trial 17 finished with value: 0.9183922046285019 and parameters: {'n_estimators': 102, 'max_depth': 27, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:20:03,531]\u001b[0m Trial 18 finished with value: 0.9907862407862409 and parameters: {'n_estimators': 200, 'max_depth': 22, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n","\u001b[32m[I 2022-06-14 23:20:05,710]\u001b[0m Trial 19 finished with value: 0.8956495284453909 and parameters: {'n_estimators': 179, 'max_depth': 27, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.9914057704112953.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["f1_score for the test set after Optuna parameter optimisation is 0.81\n"]}],"source":["def optuna_rf(trial):\n","    # Set up the hyperparameters search space\n","    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n","    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n","    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n","    \n","    # build the model\n","    model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n","                                            max_depth=max_depth,\n","                                            min_samples_leaf=min_samples_leaf,\n","                                            random_state=42)\n","    \n","    # train the model\n","    model.fit(X_train, y_train)\n","    score = metrics.f1_score(y_train, model.predict(X_train))\n","    return score\n","\n","# create the study object\n","# maximising the metric using direction=\"maximize\"\n","study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n","# search for the best hyperparameters combination n_trials times\n","study.optimize(optuna_rf, n_trials=20)\n","\n","# Calculate the metrics\n","model = ensemble.RandomForestClassifier(**study.best_params,random_state=42)\n","model.fit(X_train, y_train)\n","y_test_pred = model.predict(X_test)\n","print('f1_score for the test set after Optuna parameter optimisation is {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"]},{"cell_type":"markdown","id":"524d6d9c","metadata":{},"source":["## Conclusion"]},{"cell_type":"markdown","id":"6c60c6b8","metadata":{},"source":["### LogisticRegression\n","* f1_score for the test set (default parameters) is <b>0.78</b>\n","* GridSearchCV parameter optimisation - f1_score is <b>0.78</b> - the metric is not improved\n","* RandomizedSearchCV parameter optimisation - f1_score is <b>0.78</b> - the metric is not improved\n","* Hyperopt parameter optimisation - f1_score is <b>0.79</b> - the metric is improved\n","* Optuna parameter optimisation - f1_score is <b>0.80</b> - the metric is improved\n","\n","\n","### RandomForestClassifier\n","* f1_score for the test set (default parameters) is <b>0.80</b>\n","* GridSearchCV parameter optimisation - f1_score is <b>0.80</b> - the metric is not improved\n","* RandomizedSearchCV parameter optimisation - f1_score is <b>0.80</b> - the metric is not improved\n","* Hyperopt parameter optimisation - f1_score is <b>0.81</b> - the metric is improved\n","* Optuna parameter optimisation - f1_score is <b>0.81</b> - the metric is improved"]}],"metadata":{"colab":{"collapsed_sections":["ezanmTbEaAOe","8lbyun1kaAOy","M20nsIRfaAP-"],"name":"ML-7.Optimization of hyperparameters.ipynb","provenance":[]},"interpreter":{"hash":"b3760ce26e457f2b9f04a53ba84a92e91c37adc0c9e28d9a9495af2c4b77d101"},"kernelspec":{"display_name":"Python 3.8.11 ('sf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":5}
