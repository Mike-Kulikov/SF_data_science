{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.webintravel.com/wp-content/uploads/2019/04/GettyImages-802970402.jpg\" alt=\"car price prediction\" style=\"width:50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/mike/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mike/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "\n",
    "# Text analysis libraries\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Encoding libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Dataset split tool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Value assesment libraries\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# Machine learning libraries:\n",
    "from sklearn.ensemble import RandomForestRegressor # model creation and training tool\n",
    "from sklearn import metrics # tools for the model accuracy evaluation\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the RANDOM_SEED so that the experiments are reproducible\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the packages version so the experiments are reproducible\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data (on Kaggle)\n",
    "\n",
    "# DATA_DIR = '/kaggle/input/sf-booking/'\n",
    "# df_train = pd.read_csv(DATA_DIR+'/hotels_train.csv') \n",
    "# df_test = pd.read_csv(DATA_DIR+'hotels_test.csv') \n",
    "# sample_submission = pd.read_csv(DATA_DIR+'/submission.csv')\n",
    "\n",
    "\n",
    "# Upload the data\n",
    "\n",
    "DATA_DIR = '/home/mike/Documents/Coding/Data/Booking reviews/'\n",
    "df_train = pd.read_csv(DATA_DIR+'hotels_train.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'hotels_test.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the train and test dataframes to work with the values\n",
    "\n",
    "df_train['sample'] = 1           # Mark the train lines\n",
    "df_test['sample'] = 0            # Mark the test lines\n",
    "df_test['reviewer_score'] = 0    # There is no reviewer_score yet but we will fill it with zeros for now and predict later\n",
    "\n",
    "hotels = df_test.append(df_train, sort=False).reset_index(drop=True) # Merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates and Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the duplicates\n",
    "\n",
    "duplicates = hotels[hotels.duplicated()]\n",
    "print('Duplicates number: {}'.format(duplicates.shape[0]))\n",
    "\n",
    "# The number of duplicates is insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the nulls or missing values\n",
    "\n",
    "sns.heatmap(hotels.isnull())\n",
    "\n",
    "null_data = hotels.isnull().sum()\n",
    "display(null_data[null_data > 0])\n",
    "\n",
    "# We will deal with the nulls in 'lat' and 'lng' later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the review date into the year, month, and day of week of the review\n",
    "\n",
    "hotels['review_date'] = pd.to_datetime(hotels['review_date'], format='%m/%d/%Y')\n",
    "hotels['review_year'] = hotels['review_date'].dt.year.astype(int)\n",
    "hotels['review_month'] = hotels['review_date'].dt.month.astype(int)\n",
    "hotels['days_since_review'] = ((hotels['review_date'].max() - hotels['review_date'])/np.timedelta64(1,'D')).astype(int)\n",
    "hotels['review_day_of_week'] = hotels['review_date'].dt.dayofweek.astype(int)\n",
    "\n",
    "hotels = hotels.drop(['review_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_weekend(weekday) function takes the elements of the weekday column and\n",
    "# returns 1 if the day is a holiday and 0 if it is not.\n",
    "\n",
    "def get_weekend(weekday):\n",
    "    if weekday == 5 or weekday == 6:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "hotels['weekend'] = hotels['review_day_of_week'].apply(get_weekend)\n",
    "\n",
    "hotels = hotels.drop(['review_day_of_week'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographical locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the country, city, and zip code from the hotel address\n",
    "\n",
    "hotels['city'] = hotels.hotel_address.apply(lambda x: 'London' if x.endswith('United Kingdom') else x.split()[-2])\n",
    "hotels['country'] = hotels.hotel_address.apply(lambda x: 'United Kingdom' if x.endswith('United Kingdom') else x.split()[-1])\n",
    "hotels['zip'] = hotels.hotel_address.apply(lambda x: x.split()[-4] + ' ' + x.split()[-3] if x.endswith('United Kingdom') or x.endswith('Netherlands') else x.split()[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display where the hotels are located\n",
    "\n",
    "# create a dataframe with the names and coordinates of the hotels\n",
    "coordinates = hotels.loc[:, ('hotel_name', 'lat', 'lng')]\n",
    "\n",
    "# create a map\n",
    "px.set_mapbox_access_token(\n",
    "    'pk.eyJ1IjoicnVzczE3NCIsImEiOiJjbDE2ZWlnaGUwMTduM2NwOXY4aTE4bmtvIn0.JoLjc9UsW6b_XBukzS03zQ'\n",
    ")\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    coordinates,\n",
    "    lat=\"lat\", lon=\"lng\",\n",
    "    hover_name=\"hotel_name\",\n",
    "    size_max=15, zoom=3.5,\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={'text': \"The map of hotel locations\", 'x':0.5}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave the generalised zip codes for London\n",
    "\n",
    "def london_zip_optimiser(zip_code):\n",
    "    try:\n",
    "        zip_list = zip_code.split(' ')\n",
    "        zip_optimised = zip_list[0]\n",
    "        return zip_optimised\n",
    "    except IndexError:\n",
    "        return zip_code\n",
    "\n",
    "hotels['zip'] = hotels['zip'].apply(london_zip_optimiser)\n",
    "\n",
    "\n",
    "# group zip codes in the City zones\n",
    "def london_zip_group(zip_code):\n",
    "    wc_zip = re.findall(r'^WC', zip_code)\n",
    "    ec_zip = re.findall(r'^EC', zip_code)\n",
    "    sw1_zip = re.findall(r'^SW1', zip_code)\n",
    "    w1_zip = re.findall(r'^W1', zip_code)\n",
    "    if len(wc_zip) == 1:\n",
    "        return wc_zip[0]\n",
    "    elif len(ec_zip) == 1:\n",
    "        return ec_zip[0]\n",
    "    elif len(sw1_zip) == 1:\n",
    "        return sw1_zip[0]\n",
    "    elif len(w1_zip) == 1:\n",
    "        return w1_zip[0]\n",
    "    else:\n",
    "        return zip_code\n",
    "\n",
    "hotels['zip'] = hotels['zip'].apply(london_zip_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels['lat'] = hotels['lat'].fillna(0)\n",
    "hotels['lng'] = hotels['lng'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill up the empty lat values with the relevant city coordinates\n",
    "\n",
    "def lat_fillna(x):\n",
    "    lat = x[0]\n",
    "    city = x[1]\n",
    "    if city == 'Paris' and lat == 0:\n",
    "        return 48.8566\n",
    "    elif city == 'Vienna' and lat == 0:\n",
    "        return 48.2082\n",
    "    elif city == 'Barcelona' and lat == 0:\n",
    "        return 41.3874\n",
    "    else:\n",
    "        return lat\n",
    "    \n",
    "hotels['lat'] = hotels[['lat', 'city']].apply(lat_fillna, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill up the empty lng values with the relevant city coordinates\n",
    "\n",
    "def lng_fillna(x):\n",
    "    lng = x[0]\n",
    "    city = x[1]\n",
    "    if city == 'Paris' and lng == 0:\n",
    "        return 2.3522\n",
    "    elif city == 'Vienna' and lng == 0:\n",
    "        return 16.3738\n",
    "    elif city == 'Barcelona' and lng == 0:\n",
    "        return 2.1686\n",
    "    else:\n",
    "        return lng\n",
    "    \n",
    "hotels['lng'] = hotels[['lng', 'city']].apply(lng_fillna, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Number of Bed-nights in the Cities in 2016 (e.g. popularity)\n",
    "# Source: European Cities Marketing Benchmarking Report 2017- https://bit.ly/377Z899\n",
    "\n",
    "bednights = {\n",
    "    'Paris': 44016074, 'London': 75069660, 'Milan': 11257872, \n",
    "    'Vienna': 15760254, 'Barcelona': 19162580, 'Amsterdam': 13834000\n",
    "}\n",
    "\n",
    "hotels['city_bednights'] = hotels['city'].map(bednights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave the top 30 countries\n",
    "\n",
    "top_reviewer_nationality = list(hotels['reviewer_nationality'].value_counts()[:30].index)\n",
    "print(top_reviewer_nationality)\n",
    "hotels['reviewer_nationality'] = hotels['reviewer_nationality'].apply(lambda x: x if x in top_reviewer_nationality else ' Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the reviewer nationalities into numeric values\n",
    "\n",
    "hotels['reviewer_nationality_encoded'] = LabelEncoder().fit_transform(hotels['reviewer_nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hotel countries into numeric values identical to review nationalities\n",
    "\n",
    "def encode_some_countries(country):\n",
    "    if country == 'Austria':\n",
    "        return 1\n",
    "    if country == 'France':\n",
    "        return 5\n",
    "    if country == 'Italy':\n",
    "        return 12\n",
    "    if country == 'Netherlands':\n",
    "        return 14\n",
    "    if country == 'Spain':\n",
    "        return 23\n",
    "    if country == 'United Kingdom':\n",
    "        return 28\n",
    "\n",
    "hotels['hotel_country_encoded'] = hotels['country'].apply(encode_some_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'is_domestic' showing if the reviewer is from the same country as the hotel\n",
    "\n",
    "hotels['is_domestic'] = np.where((hotels['reviewer_nationality_encoded'] == hotels['hotel_country_encoded']), 1, 0)\n",
    "\n",
    "\n",
    "# drop the unneeded columns\n",
    "\n",
    "hotels = hotels.drop(['hotel_address', 'reviewer_nationality', 'lng', 'lat', 'hotel_country_encoded', 'country'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the average score stats\n",
    "\n",
    "hotels['average_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the average score histogram\n",
    "\n",
    "fig = px.histogram(\n",
    "    data_frame=hotels,\n",
    "    x='average_score',\n",
    "    title='Average score distribution',\n",
    "    histnorm='percent',\n",
    "    width=500,\n",
    "    marginal='box', # additional graph\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5.2 Score looks like an outlier. Let's upgrade it to 6.4\n",
    "\n",
    "hotels['average_score'] = hotels['average_score'].apply(lambda x: 6.4 if x < 6 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract traveller types from the tags\n",
    "\n",
    "def def_traveller(tag):\n",
    "    try:\n",
    "        tag_list = tag.split(',')\n",
    "        traveller_type = tag_list[1]\n",
    "        traveller_type = re.sub(r'[\\']', '', traveller_type)\n",
    "        traveller_type = re.sub(r'^\\s|\\s$', '', traveller_type)\n",
    "        return traveller_type\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "hotels['traveller_type'] = hotels['tags'].apply(def_traveller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave the top 7 most popular values. The rest mark as 'Other'\n",
    "\n",
    "popular_traveller_type = hotels['traveller_type'].value_counts().nlargest(7).index\n",
    "print(popular_traveller_type)\n",
    "hotels['traveller_type'] = hotels['traveller_type'].apply(lambda x: x if x in popular_traveller_type else ' Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trip types from the tags\n",
    "\n",
    "def def_trip_type(tag):\n",
    "    tag_list = tag.split(', ')\n",
    "    trip_type = tag_list[0]\n",
    "    if 'Leisure trip' in trip_type:\n",
    "        return 'Leisure trip'\n",
    "    elif 'Business trip' in trip_type:\n",
    "        return 'Business trip'\n",
    "    elif 'Couple' in trip_type:\n",
    "        return 'Couple'\n",
    "    elif 'Solo' in trip_type:\n",
    "        return 'Solo traveler'\n",
    "    elif 'Family' in trip_type:\n",
    "        return 'Family'\n",
    "    elif 'Group' in trip_type:\n",
    "        return 'Group'\n",
    "    elif 'pet' in trip_type:\n",
    "        return 'With a pet'\n",
    "    elif 'friends' in trip_type:\n",
    "        return 'Group'\n",
    "    else:\n",
    "        return ' Other'\n",
    "\n",
    "hotels['trip_type'] = hotels['tags'].apply(def_trip_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the length of the stay\n",
    "\n",
    "def get_stay_length(arg):\n",
    "    # find all numbers in the pattern 'Stayed D'\n",
    "    length = re.findall(r'(?<=Stayed )\\d+', arg)\n",
    "    # checking how many numbers we have\n",
    "    if len(length) == 1:\n",
    "        # saving the number of days\n",
    "        return int(length[0])\n",
    "    else:\n",
    "        # return '0' in case there is none\n",
    "        return 0\n",
    "\n",
    "hotels['stay_length'] = hotels['tags'].apply(get_stay_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the length of the stay histogram\n",
    "\n",
    "fig = px.histogram(\n",
    "    data_frame=hotels,\n",
    "    x='stay_length',\n",
    "    title='Length of stay distribution',\n",
    "    histnorm='percent',\n",
    "    width=500,\n",
    "    marginal='box', # additional graph\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all the visits longer than 7 days as 8\n",
    "\n",
    "hotels['stay_length'] = hotels['stay_length'].apply(lambda x: 8 if x > 7 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the review was left from a mobile phone\n",
    "\n",
    "def mob_device(tag):\n",
    "    tag_list = tag.split(',')\n",
    "    if 'submitted' in tag_list[-1].lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "hotels['from_mobile'] = hotels['tags'].apply(mob_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the type of rooms based on tags\n",
    "\n",
    "def room_type(tag):\n",
    "    try:\n",
    "        tag_list = tag.split(',')\n",
    "        trip_type = tag_list[2]\n",
    "        trip_type = re.sub(r'[\\']', '', trip_type)\n",
    "        trip_type = re.sub(r'^\\s|\\s$', '', trip_type)\n",
    "        return trip_type\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "hotels['room_type'] = hotels['tags'].apply(room_type)\n",
    "\n",
    "# Optimise room type value\n",
    "# Group the most common types of rooms\n",
    "\n",
    "def get_room_type(description):\n",
    "    description_list = description.split(' ')\n",
    "    if 'Suite' in description_list:\n",
    "        return ' Suite'\n",
    "    elif 'Double' in description_list:\n",
    "        return ' Double Room'\n",
    "    elif 'Single' in description_list:\n",
    "        return ' Single Room'\n",
    "    elif 'Triple' in description_list:\n",
    "        return ' Triple Room'\n",
    "    elif 'Family' in description_list:\n",
    "        return ' Family Room'\n",
    "    elif 'children' in description_list:\n",
    "        return ' Family Room'\n",
    "    elif 'King' in description_list:\n",
    "        return ' King Room'\n",
    "    elif 'Queen' in description_list:\n",
    "        return ' Queen Room'\n",
    "    elif 'Twin' in description_list:\n",
    "        return ' Twin Room'\n",
    "    elif 'Apartment' in description_list:\n",
    "        return ' Apartment'\n",
    "    elif 'Standard' in description_list:\n",
    "        return ' Standard Room'\n",
    "    elif 'Deluxe' in description_list:\n",
    "        return ' Deluxe Room'\n",
    "    elif 'Rooms' in description_list:\n",
    "        return ' Several Rooms'\n",
    "    elif 'rooms' in description_list:\n",
    "        return ' Several Rooms'\n",
    "    elif 'Stayed' in description_list:\n",
    "        return ' Other'\n",
    "    else:\n",
    "        return description\n",
    "\n",
    "# Apply the function to the room_type column\n",
    "room_types = hotels['room_type'].astype('str').apply(get_room_type)\n",
    "\n",
    "# Leave the top 12 most popular values. The rest mark as 'Others'\n",
    "popular_room_types = room_types.value_counts().nlargest(12).index\n",
    "print(popular_room_types)\n",
    "hotels['room_type'] = room_types.apply(lambda x: x if x in popular_room_types else 'other')\n",
    "\n",
    "# We don't need 'tags' anymore\n",
    "hotels = hotels.drop(['tags'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stemming the text\n",
    "\n",
    "# def simple_stemmer(text):\n",
    "#     ps=nltk.porter.PorterStemmer()\n",
    "#     text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "#     return text\n",
    "\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(simple_stemmer)\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the stopwords\n",
    "\n",
    "# # Tokenize the text\n",
    "# tokenizer=ToktokTokenizer()\n",
    "\n",
    "# # Set English stopwords\n",
    "# stopword_list=set(stopwords.words('english'))\n",
    "\n",
    "# # Function to remove stopwords\n",
    "# def remove_stopwords(text, is_lower_case=False):\n",
    "#     tokens = tokenizer.tokenize(text)\n",
    "#     tokens = [token.strip() for token in tokens]\n",
    "#     if is_lower_case:\n",
    "#         filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "#     else:\n",
    "#         filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "#     filtered_text = ' '.join(filtered_tokens)    \n",
    "#     return filtered_text\n",
    "\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(remove_stopwords)\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove special characters\n",
    "\n",
    "# def remove_special_characters(text, remove_digits=True):\n",
    "#     pattern=r'[^a-zA-z0-9\\s]'\n",
    "#     text=re.sub(pattern,'',text)\n",
    "#     return text\n",
    "\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(remove_special_characters)\n",
    "# hotels['negative_review']=hotels['negative_review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'No Negative' and similar from NEGATIVE reviews\n",
    "\n",
    "no_neg_list = ['absolutely nothing', 'all good', \"can't think of anything\",\n",
    "               'everything was great', 'everything was perfect',\n",
    "               'liked everything', 'n a', 'na', 'nil', 'no', 'no complaints',\n",
    "               'no negative', 'non', 'none', 'nothing at all', 'nothing really',\n",
    "               'nothing to complain about', 'nothing to dislike'\n",
    "              ]\n",
    "\n",
    "hotels['negative_review'] = hotels['negative_review'].str.lower().str.strip()\n",
    "hotels['negative_review'] = hotels['negative_review'].apply(lambda x: '' if x in no_neg_list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the most used words in NEGATIVE reviews\n",
    "\n",
    "text = hotels.negative_review[0]\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"hotel\", \"room\"])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Most used words in negative reviews\",fontsize=18)\n",
    "plt.axis(\"off\")\n",
    "plt.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'No Positive' and similar from POSITIVE reviews\n",
    "\n",
    "no_pos_list = ['absolutely nothing', 'all was bad', \"can't think of anything\",\n",
    "               'everything was awful', 'everything was bad',\n",
    "               \"did't like anything\", 'n a', 'na', 'nil', 'no', 'nothing',\n",
    "               'no positive', 'non', 'none',    'nothing at all', 'nothing really',\n",
    "               'nothing to like', 'nothing that stands out', 'not very much'\n",
    "              ]\n",
    "\n",
    "hotels['positive_review'] = hotels['positive_review'].str.lower().str.strip()\n",
    "hotels['positive_review'] = hotels['positive_review'].apply(lambda x: '' if x in no_pos_list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the most used words in POSITIVE reviews\n",
    "\n",
    "text = hotels.positive_review[0]\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"hotel\", \"room\"])\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      background_color=\"white\",\n",
    "                     ).generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Most used words in positive reviews\",fontsize=18)\n",
    "plt.axis(\"off\")\n",
    "plt.show('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse reviews\n",
    "\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "hotels['rw_neg'] = hotels['negative_review'].apply(lambda x: sent_analyzer.polarity_scores(x))\n",
    "hotels['rw_pos'] = hotels['positive_review'].apply(lambda x: sent_analyzer.polarity_scores(x)) \n",
    "\n",
    "\n",
    "# Record the results into the main dataframe as individual features\n",
    "\n",
    "hotels.loc[:,['n_neg', 'n_neu', 'n_pos', 'n_compound']] = list(hotels['rw_neg'].apply(lambda x: [x['neg'], x['neu'], x['pos'], x['compound']]).values)\n",
    "hotels.loc[:,['p_neg', 'p_neu', 'p_pos', 'p_compound']] = list(hotels['rw_pos'].apply(lambda x: [x['neg'], x['neu'], x['pos'], x['compound']]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc2vec vector columns for NEGATIVE reviews\n",
    "\n",
    "neg_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(hotels[\"negative_review\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "neg_model = Doc2Vec(neg_documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "neg_doc2vec_df = hotels[\"negative_review\"].apply(lambda x: neg_model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "neg_doc2vec_df.columns = [\"neg_doc2vec_vector_\" + str(x) for x in neg_doc2vec_df.columns]\n",
    "hotels = pd.concat([hotels, neg_doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc2vec vector columns for POSITIVE reviews\n",
    "\n",
    "pos_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(hotels[\"positive_review\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "pos_model = Doc2Vec(pos_documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "pos_doc2vec_df = hotels[\"positive_review\"].apply(lambda x: pos_model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "pos_doc2vec_df.columns = [\"pos_doc2vec_vector_\" + str(x) for x in pos_doc2vec_df.columns]\n",
    "hotels = pd.concat([hotels, pos_doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "\n",
    "hotels = hotels.drop(['negative_review', 'positive_review', 'rw_neg', 'rw_pos'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoder for categories\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['review_year'])\n",
    "hotels['review_year'] = ord_encoder.fit_transform(hotels['review_year'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['hotel_name'])\n",
    "hotels['hotel_name'] = ord_encoder.fit_transform(hotels['hotel_name'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['room_type'])\n",
    "hotels['room_type'] = ord_encoder.fit_transform(hotels['room_type'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['city'])\n",
    "hotels['city'] = ord_encoder.fit_transform(hotels['city'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['trip_type'])\n",
    "hotels['trip_type'] = ord_encoder.fit_transform(hotels['trip_type'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['traveller_type'])\n",
    "hotels['traveller_type'] = ord_encoder.fit_transform(hotels['traveller_type'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['zip'])\n",
    "hotels['zip'] = ord_encoder.fit_transform(hotels['zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,15))\n",
    "sns.heatmap(hotels.corr(), annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some multicollinear columns\n",
    "\n",
    "hotels = hotels.drop(['review_year'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories\n",
    "\n",
    "cat_cols = ['average_score', 'hotel_name', \n",
    "            'reviewer_nationality_encoded', 'room_type',\n",
    "            'city', 'review_month', 'trip_type', 'zip', \n",
    "            'traveller_type', 'weekend', 'is_domestic', 'from_mobile'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared test\n",
    "\n",
    "y = hotels.query('sample == 1').drop(['sample'], axis=1).reviewer_score.values.astype('int')\n",
    "X = hotels.query('sample == 1').drop(['sample'], axis=1)[cat_cols]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "imp_cat = pd.Series(chi2(X, y)[0], index=cat_cols)\n",
    "imp_cat.sort_values(inplace = True)\n",
    "imp_cat.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric features\n",
    "\n",
    "num_cols = ['stay_length', 'review_total_negative_word_counts',\n",
    "            'total_number_of_reviews', \n",
    "            'review_total_positive_word_counts', \n",
    "            'total_number_of_reviews_reviewer_has_given',\n",
    "            'days_since_review', 'city_bednights',\n",
    "            'n_neu', 'n_pos', 'n_compound',\n",
    "            'p_neg', 'p_neu', 'p_compound', \n",
    "            'additional_number_of_scoring', 'n_neg', 'p_pos',\n",
    "            'neg_doc2vec_vector_0', 'neg_doc2vec_vector_1', \n",
    "            'neg_doc2vec_vector_2', 'neg_doc2vec_vector_3', \n",
    "            'neg_doc2vec_vector_4', 'pos_doc2vec_vector_0', \n",
    "            'pos_doc2vec_vector_1', 'pos_doc2vec_vector_2', \n",
    "            'pos_doc2vec_vector_3', 'pos_doc2vec_vector_4'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of variance - ANOVA\n",
    "\n",
    "y = hotels.query('sample == 1').drop(['sample'], axis=1).reviewer_score.values.astype('int')\n",
    "X = hotels.query('sample == 1').drop(['sample'], axis=1)[num_cols]\n",
    "\n",
    "imp_num = pd.Series(f_classif(X, y)[0], index = num_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-type values encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoder for categories with less than 15 values\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['room_type', 'city', 'review_month', 'trip_type', 'traveller_type'])\n",
    "cols = encoder.fit_transform(hotels[['room_type', 'city', 'review_month', 'trip_type', 'traveller_type']])\n",
    "hotels = pd.concat([hotels, cols], axis=1)\n",
    "\n",
    "hotels = hotels.drop(['room_type', 'city', 'review_month', 'trip_type', 'traveller_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding for categories with more than 15 values\n",
    "\n",
    "bin_encoder = ce.BinaryEncoder(cols=['hotel_name', 'reviewer_nationality_encoded', 'zip'])\n",
    "type_bin = bin_encoder.fit_transform(hotels[['hotel_name', 'reviewer_nationality_encoded', 'zip']])\n",
    "hotels = pd.concat([hotels, type_bin], axis=1)\n",
    "\n",
    "hotels = hotels.drop(['hotel_name', 'reviewer_nationality_encoded', 'zip'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numeric feature are distributed abnormally and have some outliers\n",
    "# Therefore, we use Robust Scaler to avoid the outliers' influence\n",
    "\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "hotels[num_cols] = pd.DataFrame(r_scaler.fit_transform(pd.DataFrame(data = hotels[num_cols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels.head()\n",
    "\n",
    "# Nothing is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the test part\n",
    "\n",
    "train_data = hotels.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = hotels.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.reviewer_score.values            # the target\n",
    "X = train_data.drop(['reviewer_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split for splitting test data\n",
    "# Use 20% of the data for validation (test_size parameter)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shapes of the resulting datasets\n",
    "\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the test dataset\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict the rating of restaurants in the test set.\n",
    "# Record the predicted values into the 'y_pred' variable\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat the Mean Absolute Percentage Error (MAPE) function\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predicted values (y_pred) with the real ones (y_test), and assess the average difference\n",
    "# The Mean Absolute Error (MAE) metric shows the average deviation of the predicted values from the actual ones.\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the most important features for the model using RandomForestRegressor\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['reviewer_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['reviewer_score'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3760ce26e457f2b9f04a53ba84a92e91c37adc0c9e28d9a9495af2c4b77d101"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
